% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/kld-estimation-continuous.R
\name{kld_est_kde2}
\alias{kld_est_kde2}
\title{2-D density-based estimation of Kullback-Leibler divergence}
\usage{
kld_est_kde2(
  X,
  Y,
  MC = FALSE,
  hX = NULL,
  hY = NULL,
  rule = c("Silverman", "Scott"),
  eps = 1e-05
)
}
\arguments{
\item{X, Y}{Two-column matrices, representing samples from the bivariate true
distribution \eqn{P} and approximate distribution \eqn{Q}, respectively.}

\item{MC}{A boolean: use a Monte Carlo approximation instead of numerical
integration via the trapezoidal rule (default: \code{FALSE})? Currently, this
option is not implemented, i.e. a value of \code{TRUE} results in an error.}

\item{hX, hY}{Bandwidths for the kernel density estimates of \eqn{P} and \eqn{Q},
respectively. The default \code{NULL} means they are determined by argument \code{rule}.}

\item{rule}{A heuristic to derive parameters \code{hX} and \code{hY}, default is
\verb{"Silverman", which means that }\deqn{h_i = \sigma_i\left(\frac{4}{(2+d)n}\right)^{1/(d+4)}.}}

\item{eps}{A nonnegative scalar; if \code{eps > 0}, \eqn{Q} is estimated as a mixture
between the kernel density estimate and a uniform distribution on the computational
grid. The weight of the uniform component is \code{eps} times the maximum density
estimate of \eqn{Q}. Defaults to \code{eps = 1e-5}.}
}
\value{
A scalar, the estimated Kullback-Leibler divergence \eqn{D_{KL}(P||Q)}.
}
\description{
This estimation method approximates the densities of the unknown distributions
\eqn{P} and \eqn{Q} by a kernel density estimate using function 'bkde' from
package 'KernSmooth'.
}
\examples{
# KL-D between two samples from 2-D Gaussians:
X1 <- rnorm(1000)
X2 <- rnorm(1000)
Y1 <- rnorm(1000)
Y2 <- Y1 + rnorm(1000)
X <- cbind(X1,X2)
Y <- cbind(Y1,Y2)
kl_div_gaussian(mu1 = rep(0,2), sigma1 = diag(2), mu2 = rep(0,2),
                sigma2 = matrix(c(1,1,1,2),nrow=2))
kldest_density2(X,Y)
# kldest_density2(X,Y, MC = TRUE)
}
