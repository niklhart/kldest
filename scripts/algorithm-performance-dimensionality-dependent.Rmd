---
title: "Algorithm performance in large dimensions"
author: "Niklas Hartung"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(kldest)
set.seed(123456)
```


## Reproducing Figures in Wang et al. (2009)

### Fig 1 (Testing for Exponential distribution)

Simulation study design

```{r}
lambda1 <- 1
lambda2 <- 1/12         # Exp(12) in Wang et al. refers to shape parametrization
n <- c(10,50,100,200,500,1000,2000,5000,10000)
```

True KL divergence

```{r}
(kld_true <- kld_exponential(lambda1, lambda2))
```

Sampling and estimation

```{r}
nrep <- 25
kld <- matrix(NA, nrow = nrep, ncol = length(n))
for (i in seq_along(n)) {
    for (j in 1:nrep) {
        X <- as.matrix(rexp(n = n[i], rate = lambda1))
        Y <- as.matrix(rexp(n = n[i], rate = lambda2))
        kld[j,i] <- kld_est_1nn(X, Y)
    }
}
```

Plotting

```{r}
kld_mean <- colMeans(kld)
plot(x = n, y = kld_mean, type = "l", log = "x", ylab = "KL divergence",
     main = "Reproducing Figure 1 (1D exponentials)",
     ylim = range(c(kld_mean, kld_true)))
abline(h = kld_true, lty = 2)
```
Plotting (variant)

```{r}
boxplot(kld, names = n, xlab = "Sample size", ylab = "KL divergence",
     main = "Variant of Figure 1  (1D exponentials) showing variance")
abline(h = kld_true, lty = 2)
```

### Fig 2 (4-D Gaussians)

Simulation study design

```{r}
D <- 4
paramTrue   <- list(mu = c(0.1,0.3,0.6,0.9), sigma = constDiagMatrix(dim = D, diag = 1, offDiag = 0.5))
paramApprox <- list(mu = c(0,  0,  0,  0  ), sigma = constDiagMatrix(dim = D, diag = 1, offDiag = 0.1))
```


True KL divergence

```{r}
kld_true <- kld_gaussian(
    mu1    = paramTrue$mu, 
    sigma1 = paramTrue$sigma, 
    mu2    = paramApprox$mu, 
    sigma2 = paramApprox$sigma
)
kld_true
```

Sampling and estimation

```{r}
n <- c(10,50,100,200,500,1000,2000,5000,10000,20000,50000,100000)
nrep <- 25
kld <- matrix(NA, nrow = nrep, ncol = length(n))
for (i in seq_along(n)) {
    for (j in 1:nrep) {
        X <- MASS::mvrnorm(n = n[i], mu = paramTrue$mu,   Sigma = paramTrue$sigma)
        Y <- MASS::mvrnorm(n = n[i], mu = paramApprox$mu, Sigma = paramApprox$sigma)
        kld[j,i] <- kld_est_1nn(X, Y)
    }
}
```

Plotting

```{r}
kld_mean <- colMeans(kld)
plot(x = n, y = kld_mean, type = "l", log = "x", ylab = "KL divergence",
     main = "Reproducing Figure 2 (4-D Gaussians)",
     ylim = range(c(kld_mean, kld_true)))
abline(h = kld_true, lty = 2)
```

Plotting (variant)

```{r}
boxplot(kld, names = n, xlab = "Sample size", ylab = "KL divergence",
     main = "Variant of Figure 2 (4-D Gaussians) showing variance")
abline(h = kld_true, lty = 2)
```


### Fig 3 (10-D Gaussians)

Simulation study design

```{r}
D <- 10
paramTrue   <- list(mu = rep(0, D), sigma = constDiagMatrix(dim = D, diag = 1, offDiag = 0.9))
paramApprox <- list(mu = rep(0, D), sigma = constDiagMatrix(dim = D, diag = 1, offDiag = 0.1))
```


True KL divergence

```{r}
kld_true <- kld_gaussian(
    mu1    = paramTrue$mu, 
    sigma1 = paramTrue$sigma, 
    mu2    = paramApprox$mu, 
    sigma2 = paramApprox$sigma
)
kld_true
```

Sampling and estimation

```{r}
n <- c(10,50,100,200,500,1000,2000,5000,10000,20000,50000)
nrep <- 25
kld <- matrix(NA, nrow = nrep, ncol = length(n))
for (i in seq_along(n)) {
    for (j in 1:nrep) {
        X <- MASS::mvrnorm(n = n[i], mu = paramTrue$mu,   Sigma = paramTrue$sigma)
        Y <- MASS::mvrnorm(n = n[i], mu = paramApprox$mu, Sigma = paramApprox$sigma)
        kld[j,i] <- kld_est_1nn(X, Y)
    }
}
```

Plotting

```{r}
kld_mean <- colMeans(kld)
plot(x = n, y = kld_mean, type = "l", log = "x", ylab = "KL divergence",
     main = "Reproducing Figure 3 (10-D Gaussians)",
     ylim = range(c(kld_mean, kld_true)))
abline(h = kld_true, lty = 2)
```

Plotting (variant)

```{r}
boxplot(kld, names = n, xlab = "Sample size", ylab = "KL divergence",
     main = "Variant of Figure 3 (10-D Gaussians) showing variance")
abline(h = kld_true, lty = 2)
```

### Figure 5 (10-D correlated Gaussians)

Simulation study design

```{r}
D <- 10
Sigma <- constDiagMatrix(dim = D, diag = 1, offDiag = 0.999)
paramTrue   <- list(mu = rep(0, D), sigma = Sigma)
paramApprox <- list(mu = rep(1, D), sigma = Sigma)
```

True KL divergence

```{r}
kld_true <- kld_gaussian(
    mu1    = paramTrue$mu, 
    sigma1 = paramTrue$sigma, 
    mu2    = paramApprox$mu, 
    sigma2 = paramApprox$sigma
)
kld_true
```

Sampling and estimation

```{r}
n <- c(20,50,100,200,500,1000,2000,5000,10000)
nrep <- 25
kld1 <- matrix(NA, nrow = nrep, ncol = length(n))
kld2 <- matrix(NA, nrow = nrep, ncol = length(n))
for (i in seq_along(n)) {
    for (j in 1:nrep) {
        X <- MASS::mvrnorm(n = n[i], mu = paramTrue$mu,   Sigma = paramTrue$sigma)
        Y <- MASS::mvrnorm(n = n[i], mu = paramApprox$mu, Sigma = paramApprox$sigma)
        kld1[j,i] <- kld_est_1nn(X, Y)
        kld2[j,i] <- kld_est_gknn(X, Y, max.k = min(n[i]-1,50), warn.max.k = FALSE)
    }
}
```

Plotting

```{r}
kld_mean1 <- colMeans(kld1)
kld_mean2 <- colMeans(kld2)
plot(x = n, y = kld_mean1, type = "l", log = "x", ylab = "KL divergence",
     main = "Reproducing Figure 5 (10-D correlated Gaussians)",
     ylim = range(c(kld_mean1, kld_mean2, kld_true)))
lines(x = n, y = kld_mean2, col = "blue")
abline(h = kld_true, lty = 2)
legend("topright", 
       legend = c("1nn","gknn","True KL-Div."),
       lty = c(1,1,2),
       col = c("black","blue","black"))
```

Plotting (variant), `TODO`: xticks look horrible...

```{r}
boxplot(kld1, names = n, xlab = "Sample size", ylab = "KL divergence",
     main = "Variant of Figure 5 (10-D correlated Gaussians) showing variance", 
     at = 1:length(n)-0.2, boxwex = 0.25)
boxplot(kld2, add = TRUE, at = 1:length(n)+0.2, boxwex = 0.25, col = "blue", ann = FALSE)
abline(h = kld_true, lty = 2)
```



